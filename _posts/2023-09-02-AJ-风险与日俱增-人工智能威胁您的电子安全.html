---
layout: post
title: 风险与日俱增：人工智能威胁您的电子安全
date: 2023-09-02 18:36:01.000000000 +08:00
link: http://chinese.aljazeera.net/technology/2023/9/2/%e9%a3%8e%e9%99%a9%e4%b8%8e%e6%97%a5%e4%bf%b1%e5%a2%9e%e4%ba%ba%e5%b7%a5%e6%99%ba%e8%83%bd%e5%a8%81%e8%83%81%e6%82%a8%e7%9a%84%e7%94%b5%e5%ad%90%e5%ae%89%e5%85%a8
categories: aj
---

<div aria-live="polite" aria-atomic="true"><p>又是美好的一日之晨，您决定在星巴克咖啡厅完成您的工作，在那里，您点了一杯您最喜欢的饮料。您坐在位置上，准备好笔记本电脑以开始您的工作任务，并向您的经理发送了一封重要的电子邮件，并在其中告诉他，您最近需要休假。当然，您也可以在家中写下这封邮件，但这却不是我们今天要讨论的情况。现在，重要的是，咖啡厅的角落内就可能潜伏着针对您的风险。</p>
<p>当您开始在笔记本电脑的键盘上打字时，坐在您旁边的人就可以知道您通过手指在键盘上按键所写下的内容。不，他绝对不是魔法师，但他却可以使用他智能手机上的麦克风来记录您的按键声，然后再通过使用一款人工智能模型，就能将这些按键声破译为具体的词句，并了解您所写下的内容，其准确度甚至可以达到95％。</p>
<p>在其他一些情况下，这似乎是《007》系列电影中著名的间谍场景之一，但是我们可以肯定的是，它的确即将出现，因为这些技术已经开始出现，并且在日复一日地传播。</p>
<h3>窃听模型</h3>
<figure id="attachment_474459" aria-describedby="caption-attachment-474459" style="width:770px"><img loading="lazy" src="https://chinese.aljazeera.net/wp-content/uploads/2023/09/عرضي-18-1693228080-1693648822.png?w=770&amp;resize=770%2C513" alt data-recalc-dims="1" /><figcaption id="caption-attachment-474459">“边信道攻击”是一种利用计算机在不经意间释放出来的信息信号来进行破译的攻击模式 (社交网站)</figcaption></figure>
<p>来自3所英国大学的研究人员团队设法训练了一个人工智能模型，该模型可以分析智能手机麦克风录制的按键声音，并通过键盘上独特的压力分布来窃取数据，其准确度可高达95%。当他们使用Zoom应用程序来训练声音的分类算法时，其预测准确性下降至93％，当然，这仍然是极高的精确度。这种类型的攻击可被用于窃取密码，或者是在某人写下消息或与他人在笔记本电脑上交谈时找到其中的敏感信息。</p>
<p>其中的第一步是记录键盘上的按键声音，因为需要这些数据才能够训练预测算法，而这是通过附近任何带有麦克风的设备来实现的，甚至可能是目标人员自己的手机来实现的——其手机可能已经被恶意软件感染，从而使其麦克风可被控制，又或者仅仅是通过在Zoom应用程序上进行的一次通话期间记录下按键声。</p>
<p>这种类型的电子攻击被称为“边信道攻击”（side-channel attacks），它利用的是系统中的安全漏洞，即计算机在常规操作期间不经意地释放出来的信息信号。例如，这些攻击不是直接针对系统自身的算法或协议，而是针对这些算法在运行期间无意泄漏出来的信息——这些信息可以通过多种不同的方式发生泄漏，其中包括时间、电量和声音上的攻击。</p>
<p>为了简单地说明问题，我们可以这样想象，您在互联网上的一个网站内输入密码，但是有人监视着您，但他却并不试图知道您的密码本身，而是注意那些您在输入密码的过程中无意透露给他的证据。例如，在时间攻击中，想象一下，当您输入了错误的密码，那么与您输入正确密码的情况相比，网站就需要更长的时间来作出响应，通过关注这种时间上的差异，监视者可以推断出您在什么时候输入了正确的密码。</p>
<p>而在电量攻击中，部分设备在处理正确密码时消耗的电量可能要比处理错误密码时更大，通过这一点，拥有专业工具的监视者能够计算您的耗电量，并推断出您所输入的密码是否正确。</p>
<p>而在声音攻击中，当您输入密码时，不同的按键可能会发出有所区别的声音，通过这一点，仔细听取您的按键声的监视者，可以基于每个按键的独特声音来猜测您的密码。</p>
<p>与其他需要特殊条件并且受到距离限制的边信道攻击不同，声音攻击会更加容易，因为拥有麦克风以高质量捕获声音的设备广泛存在。当然，还要得益于机器学习领域内的快速发展，这使得通过声音进行边信道攻击成为可能、可行的事情，并且比过去的想象要更加危险。</p>
<h3>轻松进入领域！</h3>
<figure id="attachment_474464" aria-describedby="caption-attachment-474464" style="width:770px"><img loading="lazy" src="https://chinese.aljazeera.net/wp-content/uploads/2023/09/عرضي-19-1693228557-1693648904.png?w=770&amp;resize=770%2C513" alt data-recalc-dims="1" /><figcaption id="caption-attachment-474464">存在一些内部指令要求机器人不能作恶、不能实施霸凌，或是被用于不良目的，但是一些黑客却能绕过这些内部指令 (社交网站)</figcaption></figure>
<p>通常而言，通过依靠人工智能、机器学习、自动化及其广泛的存在和使用上的便利，黑客技术的发展降低了进入电子犯罪世界所需的技能障碍。我们不再需要理解复杂的事情，例如如何编写软件代码、使用庞大的工具与设备，就能实施电子攻击并且取得实际上的成功。此外，大型语言模型和聊天机器人（例如ChatGPT）的传播，也使事情变得更加容易，甚至这些模型的部分更新和发展就是为了训练它们以用于黑客行动。</p>
<p>在这类发展和更新中，最出名的一项技术名为“prompt injection”，它是一种新型的电子攻击技术，由于新一代聊天机器人当前在各类科技公司产品与服务中的广泛分布，这项技术已变得越来越重要、越来越危险。</p>
<p>“ChatGPT”依靠生成式人工智能技术来生成新的词语和句子，只需要您事先对它输入清晰的指令，以解释您希望从机器人那里得到什么。在幕后，存在一些内部指令要求机器人不能作恶、不能实施霸凌，或是被用于不良目的，但是一些黑客却能绕过这些内部指令，并通过逐步欺骗机器人的方式，来使它们执行一些新的命令。这种情况就好像是他们在对机器人大喊大叫，从而让它陷入混乱，并被迫执行其要求。这项技术可以被轻松运用，是因为生成式人工智能系统并不总是能够正确区分其系统内部指令和它需要处理的数据。</p>
<p>自去年11月底推出“ChatGPT”以来，这种类型的攻击已经蔓延开来——许多人利用这种攻击来欺骗机器人，以透露有关其工作原理的细节，或者重复一些充满攻击性或者令人尴尬的话语，或者在某些情况下忘记它的基本功能，并允许黑客对其重新编程以执行新的任务。例如，黑客可以要求它编写或者修改恶意软件代码，或者完成一些在过去只有专业人士才能完成的复杂事情。</p>
<p>此外，聊天机器人还能通过避免语言和拼写错误，来帮助黑客编写更为专业的欺诈性电子邮件，而在通常情况下，正是这些错误有助于检测这类欺诈性的电子邮件。它不仅可以避免拼写错误，而且还能使黑客的邮件具有一定的可信度——因为它能模仿某些人士独特的写作风格。例如，如果一个语言模型是针对特定人员编写电子邮件的方式来进行训练的，那么，它就很容易被用来模仿某个公司的高管的写作方式，并且骗到该公司内的某些员工以提供部分敏感信息，而这正是一些黑客在开发和训练类似于“ChatGPT”的聊天机器人时所希望达到的目的。</p>
<h3>专业模型</h3>
<figure id="attachment_474468" aria-describedby="caption-attachment-474468" style="width:770px"><img loading="lazy" src="https://chinese.aljazeera.net/wp-content/uploads/2023/09/عرضي-20-1693228707-1693648985.png?w=770&amp;resize=770%2C513" alt data-recalc-dims="1" /><figcaption id="caption-attachment-474468">一些人工智能语音生成软件只需要短短几句语音，就能够生成令人信服的对话，表现出讲话者的声音特征甚至是其特有的语气或情绪，而另外一些模型只需要得到讲话者持续3秒的声音 (社交网站)</figcaption></figure>
<p>在今年7月，出现了不止一个旨在促进黑客行动的语言模型，其中第一个名叫“WormGPT”，其运行基于开源语言模型“GPT-J”，其开发者在不同的数据库上训练该机器人，并重点关注与恶意软件相关的数据。就在同月，出现了另一个名为“FraudGPT”的机器人，黑客们在“暗网”上宣传它是专为欺诈、电子入侵、黑客攻击和网络犯罪而设计的机器人。</p>
<p>开发此类机器人的目标，是为了简化编写令人信服或看似真实的欺诈性电子邮件的过程，而更为重要的是，它是为目标人员量身定制的，从而提高了电子攻击成功的机会。</p>
<p>这些语言模型的潜力不仅限于简化写作过程、避免拼写错误或者模仿人类的写作方式，而且还能够通过机器学习的分析技能，来确定某组织内部的最佳目标人员以及如何对其开展攻击。</p>
<p>例如，假设一家公司的一名会计师在其Facebook账户上发帖吐槽他对公司管理层最近的审计过程感到沮丧和不满。届时，人工智能模型便可以识别出该会计师的同事，以及该公司的管理结构，还有该公司内部其他任何容易受到攻击的人员。然后，黑客便可以编写一封欺诈性电子邮件，自称是公司首席财务官，并指出在最近的审计过程中存在一些问题，并要求目标人员点击包含病毒或者恶意软件的电子表格附件链接，以窃取数据。</p>
<p>除了以上这些，我们还将谈到可以模拟人类声音和说话方式的人工智能模型，诈骗者们利用这类模型来模仿目标人员亲友的声音，然后向目标人员寻求帮助，以诈骗他们数千美元的资金。一些人工智能语音生成软件只需要短短几句语音，就能够生成令人信服的对话，表现出讲话者的声音特征甚至是其特有的语气或情绪，而另外一些模型只需要得到讲话者持续3秒的声音。对于目标受害者（通常是老年人）而言，即使诈骗者所描述的紧急情况听起来很不可信，他们通常也很难辨别这些声音究竟是真实的还是合成的。</p>
<p>除此之外，还存在利用人工智能伪造视频的知名技术。该技术在过去几年内以“深度伪造”（Deepfake）之名为人所知，通过这项技术，可以制作出貌似真实的视频——甚至可以生成美国总统拜登向中国宣战的虚假内容。当然，这只是为了说明其严重性而提出的夸张说法。</p>
<h3>不予信任的模式！</h3>
<figure id="attachment_474472" aria-describedby="caption-attachment-474472" style="width:770px"><img loading="lazy" src="https://chinese.aljazeera.net/wp-content/uploads/2023/09/عرضي-21-1693228946-1693649059.png?w=770&amp;resize=770%2C513" alt data-recalc-dims="1" /><figcaption id="caption-attachment-474472">我们必须在所有的数字互动中保持谨慎。如果一条消息或者通话引起了我们的任何怀疑，那么我们决不能点击其中的任何链接，或者下载其中的任何文件 (社交网站)</figcaption></figure>
<p>一般来说，在这个距离相近的世界上，互联网上的一切看起来可能都是合理的，或者​​合法的，但是从今之后，我们不再能够相信任何东西，因为诈骗过程已经比以往任何时候都更快、更容易。当前的另一个困境是，我们没有足够的时间——无论是几个月还是几周——来研究所有这些问题，因为它们正以极快的速度发展——我们根本跟不上这种发展，也无力对其进行观察和学习，而它们就已经来到了我们身边，并开始投入实际使用。</p>
<p>因此，对自身和电子安全的保护，取决于您对眼前不断看到和经历的事物的信心。这似乎是显而易见的，但是我们需要永远记住这一点。现在，我们必须在所有的数字互动中保持谨慎。如果一条消息或者通话引起了我们的任何怀疑，那么我们决不能点击其中的任何链接，或者下载其中的任何文件，更不用说是向与您通信的任何人员提供任何个人信息或者机密信息——无论对方身份如何。</p>
<p>这种方法被称为“零信任安全模式”（Zero trust security model），顾名思义，这意味着我们不会假定信任任何事情或者任何个人，并且要在向他人提供我们数据的访问权限之前，去验证并核实每个设备、用户、服务或者其他任何事物的可信度，并且还必须经常重新验证其可靠性，以确保在使用过程中不会受到损害。</p>
<p>然后是使自身行为难以预测，例如，开发根据按键声推测内容的模型的研究人员建议，改变打字模式，并使用随机密码，而不要包含可被理解的句子或单词。如果您在Zoom应用程序上通话时正在打字，那么您可以在键盘上随意按下一些毫无意义的按键，以避免对方记录到您写下的任何内容，尤其是当您写邮件给经理，告知对方您需要休假的时候！</p>
</div><div>来源<!-- --> : <!-- -->半岛电视台</div>
